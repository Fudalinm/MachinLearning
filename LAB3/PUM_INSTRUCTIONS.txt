A: Wróćmy do hiperkuli wpisanej w hipersześcian z pierwszego zadania. Pokolorujmy na czubkach narożników sześcianu na czerwono, punkty na krawędziach na żółto (mogą wymagać dodatkowej generacji, bo w losowym rozkładzie się raczej nie pojawią), punkty w jego wnętrzu (ale nie we wnętrzu kuli) na niebiesko, a punkty z kuli na zielono. Schemat kolorów przykładowy, każdy inny który pozwoli odróżnić elementy będzie ok. Wykorzystać metodę PCA by wykonać wizualizację (rzut na płaszczyznę 2D) tejże sytuacji dla 3, 4, 5, 7 i 13 wymiarów. Powtórzyć to samo, ale dla wizualizacji 3D. Krótko opisać co widać. ;]

B: Wygenerujmy zbiór danych wyglądający +- tak, jak na rysunku w załączniku (punkty w różnych kolorach należą do różnych klas). Potraktujmy go klasycznym PCA. Przygotujmy diagram prezentujący rozkład punktów w nowo znalezionej przestrzeni. Nanieśmy również na pierwotny rysunek strzałki prezentujące wektory będące znalezionymi "principal components" (gdzie długość wektora jest proporcjonalna do wariancji przez niego wyjaśnianej). Spoiler - efekty będą dość trywialne (mapowanie z 2D w inne 2D). Można próbować uzyskać więcej stosując tzw. kernel trick - zamiast klasycznego iloczynu skalarnego wykorzysztać inną, odpowiednio spreparowaną funkcję. Zrzutujmy więc oba zbiory w nową przestrzeń, ale tym razem wykorzystując kernel PCA z kernelami "cosine" (tu warto sprawdzić jaki wpływ na wynik będzie miało wcześniejsze wyśrodkowanie danych lub jego brak) i "rbf" (radial basis function - tu należy sprawdzić różne wartości parametru gamma wpływającego na pracę kernela, w tym także bardzo małe) oraz przygotujmy diagramy prezentujące efekty.

#####################################################

Robimy sobie i bliskim/współlokatorkom/współlokatorom/innym znajomym 15+ (ale im więcej tym lepiej) różnych selfie (z możliwie tym samym tłem i oświetleniem, niekoniecznie z tym samym wyrazem twarzy) (jeżeli mieszkamy sami - robimy je tylko sobie, ale wykorzystujemy talent aktorski i na 15+ jesteśmy radośni, a na 15+ przygnębieni, etc.). Generalnie im większy i bogatszy zbiór, tym ciekawsze będą wyniki. Warto też zadbać, by twarze na zdjęciach były jak najlepiej wyśrodkowane (nie muszą być wyśrodkowane idealnie), patrzyły do przodu i miały możliwie jednorodne tło (oczywiście to nigdy nie uda się idealnie - proszę zwrócić uwagę jak drobne niedoskonałości wpłyną na wyniki). Przy tworzeniu zbioru można też współpracować z innymi studentami z tego kursu. ;] Jeżeli wolelibyśmy nie gromadzić tego typu danych, to tworzony zbiór może zawierać inne obiekty - powinny jednak być tego samego typu i na takim samym ujęciu.

Konwertujemy je do czerni i bieli oraz zmniejszamy ich rozdzielczość (jak silnie? tak, aby obliczenia nie trwały zbyt długo). Traktujemy je jako zbiór n*(15+) elementów należących do n klas. Dokonujemy zamiany zdjęć na wektory i przeprowadzamy na takim zbiorze PCA (zwykłe, nie kernel).

Jak wygląda "średnia twarz?". Jak wyglądają kolejne "principal components" (są bardzo długimi wektorami, ale możemy je przekonwertować ponownie na zdjęcia i tak zaprezentować)? Zauważmy też, że tylko niewielka część nowych wektorów bazowych ma istotny udział w tłumaczeniu pierwotnej wariancji zbioru (explained variance ratio). Jak wyglądają zrekonstruowane twarze, jeżeli obetniemy przestrzeń do 5, 15 i 50 najważniejszych? Na koniec, ograniczmy przestrzeń do 2 najważniejszych wymiarów i zrzutujmy elementy zbioru na płaszczyznę 2D (kolorując punkty w zależności od klasy do której przynależą). Czy są łatwo separowalne?

Na koniec dokonajmy tej samej transformacji, ale z użyciem SparsePCA (z dużym naciskiem na to, by wynikowe wektory były rzadkie). Jak zmieniły się wyniki. Które piksele pierwotnych obrazów mają największe wagi w pierwszych dwóch składowych?